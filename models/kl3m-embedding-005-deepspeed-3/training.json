{
  "tokenizer": "alea-institute/kl3m-003-64k",
  "precision": "bfloat16",
  "batch_size": 96,
  "endpoint_url": "http://localhost:8000/",
  "matroyshka_probability": 0.5,
  "steps_per_epoch": 1000000,
  "steps_per_save": 1000,
  "tasks": {
    "mlm": 0.5,
    "nsp": 0.5
  },
  "optimizer": {
    "scheduler_type": "exponential",
    "start_lr": 0.0000001,
    "end": 0.0000001,
    "warmup_factor": 2.0,
    "warmup_steps_per_period": 100,
    "warmup_periods": 10,
    "constant_steps": 100,
    "cooldown_factor": 1.5,
    "cooldown_steps_per_period": 100,
    "cooldown_periods": 10,
    "max_grad_norm": 8.0
  },
  "deepspeed": {
    "gradient_accumulation_steps": 4,
    "bf16": {
      "enabled": true
    },
    "zero_optimization": {
      "stage": 3,
      "allgather_partitions": true,
      "allgather_bucket_size": 16777216,
      "overlap_comm": true,
      "reduce_scatter": true,
      "reduce_bucket_size": 16777216,
      "contiguous_gradients": true,
      "ignore_unused_parameters": false,
      "stage3_gather_16bit_weights_on_model_save": true,
      "offload_optimizer": {
        "device": "cpu",
        "pin_memory": true
      },
      "offload_param": {
          "device": "cpu",
          "pin_memory": true
      }
    }
  }
}
