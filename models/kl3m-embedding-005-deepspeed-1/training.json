{
  "tokenizer": "alea-institute/kl3m-003-64k",
  "precision": "bfloat16",
  "batch_size": 64,
  "endpoint_url": "http://localhost:8000/",
  "matroyshka_probability": 0.5,
  "steps_per_epoch": 1000000,
  "steps_per_save": 1000,
  "steps_per_eval": 1000,
  "num_eval_samples": 1000,
  "tasks": {
    "mlm": 0.75,
    "nsp": 0.1,
    "nlp": 0.1,
    "mhm": 0.05
  },
  "optimizer": {
    "start_lr": 0.00001,
    "peak_lr": 0.0002,
    "end_lr": 0.0001,
    "warmup_steps": 1000,
    "peak_steps": 9000,
    "total_steps": 200000,
    "max_grad_norm": 1.0
  },
  "deepspeed": {
    "optimizer_type": "fused_adamw",
    "gradient_accumulation_steps": 1,
    "bf16": {
      "enabled": true
    },
    "zero_optimization": {
      "stage": 1,
      "allgather_partitions": true,
      "allgather_bucket_size": 16777216,
      "overlap_comm": true,
      "reduce_scatter": true,
      "reduce_bucket_size": 16777216,
      "contiguous_gradients": true
    }
  }
}
